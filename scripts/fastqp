#!/usr/bin/python

from __future__ import division
import os
import sys
import argparse
import itertools
import random
import fastqp
import math
import time

def mean(s):
    return sum(s) / len(s)

def run(args):
    """ read FASTQ or SAM and tabulate basic metrics """
    time_start = time.time()
    bsize = os.path.getsize(args.input)
    
    ## estimate the number of lines in args.input
    current_entry = int()
    sample_lengths = list()
    sample_binsizes = list()
    with fastqp.reader(args.input, format=args.type, bincheck=True) as infile:
        while current_entry < 1000:
            line = iter(infile).next()
            sample_lengths.append(len(line[1]))
            sample_binsizes.append(line[0])
            current_entry += 1
    mean_bentry = mean(sample_binsizes)
    mean_len = mean(sample_lengths)
    est_nlines = int(bsize / mean_bentry)
    act_nlines = int()
    if not args.quiet:
        sys.stderr.write("At {bytes:.0f} bytes per read of {len:.0f} length we estimate {est:,} reads in input file.\n".format(bytes=mean_bentry,
                                                                                                               len=mean_len,
                                                                                                               est=est_nlines))                                                                                                               
    ## set up factor for sampling bin size                                                                                                                   
    if args.sample:
        n = args.sample
    else:
        nf = math.floor(est_nlines / 200000)
        if nf >=1:
            n = int(nf)
        else:
            n = 1
    if not args.quiet:
        sys.stderr.write("Bin size (-s) set to {binsize:n}.\n".format(binsize=n))        
    with fastqp.reader(args.input, format=args.type) as infile, fastqp.stats() as stats:
        percent_complete = 10
        reads = itertools.islice(infile, None, None, n)
        for read in reads:
            stats.evaluate(read)
            if not args.nokmer:
                stats.kmercount(read, args.kmer)
            if not args.quiet:
                if (act_nlines / est_nlines) * 100 >= percent_complete:
                    sys.stderr.write("Approximately {0:n}% complete at read {1:,} in {2}\n".format(percent_complete, act_nlines,
                                                                                                 time.strftime('%H:%M:%S',
                                                                                                               time.gmtime(time.time()-time_start))))
                    percent_complete += 10
            act_nlines += n
        stats.summarize(filename=args.output, figures=args.figures)
        time_finish = time.time()
        elapsed = time_finish - time_start
        if not args.quiet:
            sys.stderr.write("There were approximately {counts:,} reads in the file. Analysis finished in {sec}.\n".format(counts=act_nlines,
                                                                                                                      sec=time.strftime('%H:%M:%S',
                                                                                                                          time.gmtime(elapsed))
                                                                                                                          ))
        
def main():
    parser = argparse.ArgumentParser(prog='fastqp', description="simple NGS read quality assessment using Python", 
                                     epilog=""" Note: fastqp randomly samples ~200,000 reads from the input file by default. 
                                                To change the number of reads sample, specify the number of reads to bin for 
                                                sampling. For example, '-s 100' will sample 1 in 100 reads. To evaluate the 
                                                entire file set '-s 1'. """)
    parser.add_argument('input', type=str, help="input file(.gz))")
    parser.add_argument('-q', '--quiet', action="store_true", default=False, help="do not print any messages")
    parser.add_argument('-s', '--sample', type=int, help='number of reads to bin for sampling')
    parser.add_argument('-k', '--kmer', type=int, default=5, choices=range(2, 11), help='length of kmer for over-repesented kmer counts')
    parser.add_argument('-o', '--output', type=str, help="base name for output files")
    parser.add_argument('-t', '--type', type=str, default='fastq', choices=('sam', 'fastq'), help="file type for input file (default=fastq)")
    parser.add_argument('-f', '--figures', action="store_true", default=False, help="produce figures")
    parser.add_argument('--nokmer', action="store_true", default=False, help="do not count kmers")
    
    args = parser.parse_args()
    run(args)

if __name__ == "__main__": 
    main()
